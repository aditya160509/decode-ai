{
  "definitions": [
    "A token is a small chunk of text (word, subword, or symbol).",
    "A context window is the max number of tokens a model can consider at once."
  ],
  "examples": [
    "\"ChatGPT is smart.\" -> ~4-5 tokens.",
    "\"AI\" -> ~1 token.",
    "\"Unbelievable!\" -> ~2-3 tokens.",
    "Short prompt: \"Summarize this article.\" -> few tokens.",
    "Long prompt: includes thousands of tokens; may exceed limits.",
    "Token cost: usage/limits often based on tokens.",
    "Overflow: too-long inputs push out earlier tokens."
  ],
  "visual": "Bar showing tokens used vs available"
}
